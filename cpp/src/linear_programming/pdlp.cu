/* clang-format off */
/*
 * SPDX-FileCopyrightText: Copyright (c) 2022-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 * SPDX-License-Identifier: Apache-2.0
 */
/* clang-format on */

#include <cuopt/error.hpp>
#include <cuopt/linear_programming/pdlp/pdlp_hyper_params.cuh>
#include <cuopt/linear_programming/pdlp/pdlp_warm_start_data.hpp>
#include <cuopt/linear_programming/solver_settings.hpp>
#include <linear_programming/pdlp.cuh>
#include <linear_programming/utils.cuh>
#include <mip/mip_constants.hpp>
#include "cuopt/linear_programming/pdlp/solver_solution.hpp"

#include <utilities/copy_helpers.hpp>

#include <raft/sparse/detail/cusparse_macros.h>
#include <raft/sparse/detail/cusparse_wrappers.h>
#include <raft/common/nvtx.hpp>
#include <raft/linalg/eltwise.cuh>
#include <raft/linalg/ternary_op.cuh>

#include <rmm/device_buffer.hpp>
#include <rmm/device_scalar.hpp>
#include <rmm/device_uvector.hpp>

#include <cub/cub.cuh>

#include <thrust/count.h>
#include <thrust/extrema.h>

#include <optional>

namespace cuopt::linear_programming::detail {

void set_pdlp_hyper_parameters(rmm::cuda_stream_view stream_view)
{
  RAFT_CUDA_TRY(cudaMemcpyToSymbolAsync(pdlp_hyper_params::primal_importance,
                                        &pdlp_hyper_params::host_primal_importance,
                                        sizeof(double),
                                        0,
                                        cudaMemcpyHostToDevice,
                                        stream_view));
}

template <typename i_t, typename f_t>
pdlp_solver_t<i_t, f_t>::pdlp_solver_t(problem_t<i_t, f_t>& op_problem,
                                       pdlp_solver_settings_t<i_t, f_t> const& settings,
                                       bool is_batch_mode)
  : handle_ptr_(op_problem.handle_ptr),
    stream_view_(handle_ptr_->get_stream()),
    problem_ptr(&op_problem),
    op_problem_scaled_(
      op_problem, false),  // False to call the PDLP custom version of the problem copy constructor
    unscaled_primal_avg_solution_{static_cast<size_t>(op_problem.n_variables), stream_view_},
    unscaled_dual_avg_solution_{static_cast<size_t>(op_problem.n_constraints), stream_view_},
    primal_size_h_(op_problem.n_variables),
    dual_size_h_(op_problem.n_constraints),
    primal_step_size_{stream_view_},
    dual_step_size_{stream_view_},
    primal_weight_{stream_view_},
    best_primal_weight_{stream_view_},
    step_size_{(f_t)pdlp_hyper_params::initial_step_size_scaling, stream_view_},
    step_size_strategy_{handle_ptr_, &primal_weight_, &step_size_, is_batch_mode},
    pdhg_solver_{handle_ptr_, op_problem_scaled_, is_batch_mode},
    settings_(settings),
    initial_scaling_strategy_{handle_ptr_,
                              op_problem_scaled_,
                              pdlp_hyper_params::default_l_inf_ruiz_iterations,
                              (f_t)pdlp_hyper_params::default_alpha_pock_chambolle_rescaling,
                              op_problem_scaled_.reverse_coefficients,
                              op_problem_scaled_.reverse_offsets,
                              op_problem_scaled_.reverse_constraints,
                              &pdhg_solver_},
    average_op_problem_evaluation_cusparse_view_{handle_ptr_,
                                                 op_problem,
                                                 unscaled_primal_avg_solution_,
                                                 unscaled_dual_avg_solution_,
                                                 pdhg_solver_.get_primal_tmp_resource(),
                                                 pdhg_solver_.get_dual_tmp_resource(),
                                                 pdhg_solver_.get_potential_next_primal_solution(),
                                                 pdhg_solver_.get_potential_next_dual_solution(),
                                                 op_problem.reverse_coefficients,
                                                 op_problem.reverse_offsets,
                                                 op_problem.reverse_constraints},
    current_op_problem_evaluation_cusparse_view_{handle_ptr_,
                                                 op_problem,
                                                 pdhg_solver_.get_primal_solution(),
                                                 pdhg_solver_.get_dual_solution(),
                                                 pdhg_solver_.get_primal_tmp_resource(),
                                                 pdhg_solver_.get_dual_tmp_resource(),
                                                 pdhg_solver_.get_potential_next_primal_solution(),
                                                 pdhg_solver_.get_potential_next_dual_solution(),
                                                 op_problem.reverse_coefficients,
                                                 op_problem.reverse_offsets,
                                                 op_problem.reverse_constraints},
    restart_strategy_{handle_ptr_,
                      op_problem,
                      average_op_problem_evaluation_cusparse_view_,
                      primal_size_h_,
                      dual_size_h_,
                      is_batch_mode},
    average_termination_strategy_{handle_ptr_,
                                  op_problem,
                                  average_op_problem_evaluation_cusparse_view_,
                                  primal_size_h_,
                                  dual_size_h_,
                                  settings_},
    current_termination_strategy_{handle_ptr_,
                                  op_problem,
                                  current_op_problem_evaluation_cusparse_view_,
                                  primal_size_h_,
                                  dual_size_h_,
                                  settings_},
    initial_primal_{0, stream_view_},
    initial_dual_{0, stream_view_},

    best_primal_solution_so_far{pdlp_termination_status_t::TimeLimit, stream_view_},
    inside_mip_{false}
{
  if (settings.has_initial_primal_solution()) {
    auto& primal_sol = settings.get_initial_primal_solution();
    set_initial_primal_solution(primal_sol);
  }
  if (settings.has_initial_dual_solution()) {
    const auto& dual_sol = settings.get_initial_dual_solution();
    set_initial_dual_solution(dual_sol);
  }

  if (settings.get_pdlp_warm_start_data().last_restart_duality_gap_dual_solution_.size() != 0) {
    set_initial_primal_solution(settings.get_pdlp_warm_start_data().current_primal_solution_);
    set_initial_dual_solution(settings.get_pdlp_warm_start_data().current_dual_solution_);
    initial_step_size_     = settings.get_pdlp_warm_start_data().initial_step_size_;
    initial_primal_weight_ = settings.get_pdlp_warm_start_data().initial_primal_weight_;
    total_pdlp_iterations_ = settings.get_pdlp_warm_start_data().total_pdlp_iterations_;
    pdhg_solver_.total_pdhg_iterations_ =
      settings.get_pdlp_warm_start_data().total_pdhg_iterations_;
    pdhg_solver_.get_d_total_pdhg_iterations().set_value_async(
      settings.get_pdlp_warm_start_data().total_pdhg_iterations_, stream_view_);
    restart_strategy_.last_candidate_kkt_score =
      settings.get_pdlp_warm_start_data().last_candidate_kkt_score_;
    restart_strategy_.last_restart_kkt_score =
      settings.get_pdlp_warm_start_data().last_restart_kkt_score_;
    raft::copy(restart_strategy_.weighted_average_solution_.sum_primal_solutions_.data(),
               settings.get_pdlp_warm_start_data().sum_primal_solutions_.data(),
               settings.get_pdlp_warm_start_data().sum_primal_solutions_.size(),
               stream_view_);
    raft::copy(restart_strategy_.weighted_average_solution_.sum_dual_solutions_.data(),
               settings.get_pdlp_warm_start_data().sum_dual_solutions_.data(),
               settings.get_pdlp_warm_start_data().sum_dual_solutions_.size(),
               stream_view_);
    raft::copy(unscaled_primal_avg_solution_.data(),
               settings.get_pdlp_warm_start_data().initial_primal_average_.data(),
               settings.get_pdlp_warm_start_data().initial_primal_average_.size(),
               stream_view_);
    raft::copy(unscaled_dual_avg_solution_.data(),
               settings.get_pdlp_warm_start_data().initial_dual_average_.data(),
               settings.get_pdlp_warm_start_data().initial_dual_average_.size(),
               stream_view_);
    raft::copy(pdhg_solver_.get_saddle_point_state().get_current_AtY().data(),
               settings.get_pdlp_warm_start_data().current_ATY_.data(),
               settings.get_pdlp_warm_start_data().current_ATY_.size(),
               stream_view_);
    raft::copy(restart_strategy_.last_restart_duality_gap_.primal_solution_.data(),
               settings.get_pdlp_warm_start_data().last_restart_duality_gap_primal_solution_.data(),
               settings.get_pdlp_warm_start_data().last_restart_duality_gap_primal_solution_.size(),
               stream_view_);
    raft::copy(restart_strategy_.last_restart_duality_gap_.dual_solution_.data(),
               settings.get_pdlp_warm_start_data().last_restart_duality_gap_dual_solution_.data(),
               settings.get_pdlp_warm_start_data().last_restart_duality_gap_dual_solution_.size(),
               stream_view_);

    const auto value = settings.get_pdlp_warm_start_data().sum_solution_weight_;
    restart_strategy_.weighted_average_solution_.sum_primal_solution_weights_.set_value_async(
      value, stream_view_);
    restart_strategy_.weighted_average_solution_.sum_dual_solution_weights_.set_value_async(
      value, stream_view_);
    restart_strategy_.weighted_average_solution_.iterations_since_last_restart_ =
      settings.get_pdlp_warm_start_data().iterations_since_last_restart_;
  }
  // Checks performed below are assert only
  best_primal_quality_so_far_.primal_objective = (op_problem_scaled_.maximize)
                                                   ? -std::numeric_limits<f_t>::infinity()
                                                   : std::numeric_limits<f_t>::infinity();
  op_problem.check_problem_representation(true, false);
  op_problem_scaled_.check_problem_representation(true, false);
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::set_initial_primal_weight(f_t initial_primal_weight)
{
  initial_primal_weight_ = initial_primal_weight;
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::set_initial_step_size(f_t initial_step_size)
{
  initial_step_size_ = initial_step_size;
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::set_initial_k(i_t initial_k)
{
  initial_k_ = initial_k;
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::set_relative_dual_tolerance_factor(f_t dual_tolerance_factor)
{
  average_termination_strategy_.set_relative_dual_tolerance_factor(dual_tolerance_factor);
  current_termination_strategy_.set_relative_dual_tolerance_factor(dual_tolerance_factor);
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::set_relative_primal_tolerance_factor(f_t primal_tolerance_factor)
{
  average_termination_strategy_.set_relative_primal_tolerance_factor(primal_tolerance_factor);
  current_termination_strategy_.set_relative_primal_tolerance_factor(primal_tolerance_factor);
}

template <typename i_t, typename f_t>
f_t pdlp_solver_t<i_t, f_t>::get_relative_dual_tolerance_factor() const
{
  return current_termination_strategy_.get_relative_dual_tolerance_factor();
}

template <typename i_t, typename f_t>
f_t pdlp_solver_t<i_t, f_t>::get_relative_primal_tolerance_factor() const
{
  return current_termination_strategy_.get_relative_primal_tolerance_factor();
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::set_initial_primal_solution(
  const rmm::device_uvector<f_t>& initial_primal_solution)
{
  initial_primal_.resize(initial_primal_solution.size(), stream_view_);
  raft::copy(initial_primal_.data(),
             initial_primal_solution.data(),
             initial_primal_solution.size(),
             stream_view_);
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::set_initial_dual_solution(
  const rmm::device_uvector<f_t>& initial_dual_solution)
{
  initial_dual_.resize(initial_dual_solution.size(), stream_view_);
  raft::copy(
    initial_dual_.data(), initial_dual_solution.data(), initial_dual_solution.size(), stream_view_);
}

static bool time_limit_reached(const timer_t& timer) { return timer.check_time_limit(); }

template <typename i_t, typename f_t>
std::optional<optimization_problem_solution_t<i_t, f_t>> pdlp_solver_t<i_t, f_t>::check_limits(
  const timer_t& timer)
{
  // Check for time limit
  if (time_limit_reached(timer)) {
    if (settings_.save_best_primal_so_far) {
#ifdef PDLP_VERBOSE_MODE
      RAFT_CUDA_TRY(cudaDeviceSynchronize());
      std::cout << "Time Limit reached, returning best primal so far" << std::endl;
#endif
      return std::move(best_primal_solution_so_far);
    }
#ifdef PDLP_VERBOSE_MODE
    RAFT_CUDA_TRY(cudaDeviceSynchronize());
    std::cout << "Time Limit reached, returning current solution" << std::endl;
#endif
    return current_termination_strategy_.fill_return_problem_solution(
      internal_solver_iterations_,
      pdhg_solver_,
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_primal_solution()
        : pdhg_solver_.get_potential_next_primal_solution(),
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_dual_solution()
        : pdhg_solver_.get_potential_next_dual_solution(),
      get_filled_warmed_start_data(),
      pdlp_termination_status_t::TimeLimit);
  }

  // Check for iteration limit
  if (internal_solver_iterations_ >= settings_.iteration_limit) {
    if (settings_.save_best_primal_so_far) {
#ifdef PDLP_VERBOSE_MODE
      RAFT_CUDA_TRY(cudaDeviceSynchronize());
      std::cout << "Iteration Limit reached, returning best primal so far" << std::endl;
#endif
      best_primal_solution_so_far.set_termination_status(pdlp_termination_status_t::IterationLimit);
      return std::move(best_primal_solution_so_far);
    }
#ifdef PDLP_VERBOSE_MODE
    RAFT_CUDA_TRY(cudaDeviceSynchronize());
    std::cout << "Iteration Limit reached, returning current solution" << std::endl;
#endif

    return current_termination_strategy_.fill_return_problem_solution(
      internal_solver_iterations_,
      pdhg_solver_,
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_primal_solution()
        : pdhg_solver_.get_potential_next_primal_solution(),
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_dual_solution()
        : pdhg_solver_.get_potential_next_dual_solution(),
      get_filled_warmed_start_data(),
      pdlp_termination_status_t::IterationLimit);
  }

  // Check for concurrent limit
  if (settings_.method == method_t::Concurrent && settings_.concurrent_halt != nullptr &&
      *settings_.concurrent_halt == 1) {
#ifdef PDLP_VERBOSE_MODE
    RAFT_CUDA_TRY(cudaDeviceSynchronize());
    std::cout << "Concurrent Limit reached, returning current solution" << std::endl;
#endif
    return current_termination_strategy_.fill_return_problem_solution(
      internal_solver_iterations_,
      pdhg_solver_,
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_primal_solution()
        : pdhg_solver_.get_potential_next_primal_solution(),
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_dual_solution()
        : pdhg_solver_.get_potential_next_dual_solution(),
      get_filled_warmed_start_data(),
      pdlp_termination_status_t::ConcurrentLimit);
  }

  return std::nullopt;
}

// True if current has a better primal objective value based on if minimize or maximize
template <typename f_t>
static bool is_current_objective_better(f_t current_primal_objective,
                                        f_t other_primal_objective,
                                        bool maximize)
{
  const bool current_is_lower = current_primal_objective < other_primal_objective;
  return (!maximize && current_is_lower) || (maximize && !current_is_lower);
}

// Returns the solution with the best quality
template <typename i_t, typename f_t>
const pdlp_solver_t<i_t, f_t>::primal_quality_adapter_t& pdlp_solver_t<i_t, f_t>::get_best_quality(
  const pdlp_solver_t<i_t, f_t>::primal_quality_adapter_t& current,
  const pdlp_solver_t<i_t, f_t>::primal_quality_adapter_t& other)
{
#ifdef PDLP_DEBUG_MODE
  RAFT_CUDA_TRY(cudaDeviceSynchronize());
  std::cout << "  current.is_primal_feasible = " << current.is_primal_feasible << std::endl;
  std::cout << "  current.nb_violated_constraints = " << current.nb_violated_constraints
            << std::endl;
  std::cout << "  current.primal_residual = " << current.primal_residual << std::endl;
  std::cout << "  current.primal_objective = " << current.primal_objective << std::endl;
  std::cout << "  other.is_primal_feasible = " << other.is_primal_feasible << std::endl;
  std::cout << "  other.nb_violated_constraints = " << other.nb_violated_constraints << std::endl;
  std::cout << "  other.primal_residual = " << other.primal_residual << std::endl;
  std::cout << "  other.primal_objective = " << other.primal_objective << std::endl;
#endif

  // Primal feasiblity is best

  if (current.is_primal_feasible && !other.is_primal_feasible)
    return current;
  else if (!current.is_primal_feasible && other.is_primal_feasible)
    return other;
  else if (current.is_primal_feasible && other.is_primal_feasible) {
    // Then objective is best
    const bool current_objective_is_better = is_current_objective_better(
      current.primal_objective, other.primal_objective, op_problem_scaled_.maximize);
    return (current_objective_is_better) ? current : other;
  }

  // Both are not primal feasible

  // Prioritize least overall residual
  if (current.primal_residual < other.primal_residual)
    return current;
  else
    return other;
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::set_inside_mip(bool inside_mip)
{
  inside_mip_ = inside_mip;
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::record_best_primal_so_far(
  const detail::pdlp_termination_strategy_t<i_t, f_t>& current,
  const detail::pdlp_termination_strategy_t<i_t, f_t>& average,
  const pdlp_termination_status_t& termination_current,
  const pdlp_termination_status_t& termination_average)
{
#ifdef PDLP_VERBOSE_MODE
  RAFT_CUDA_TRY(cudaDeviceSynchronize());
  std::cout << "Recording best primal so far" << std::endl;
#endif

  // As this point, neither current or average are pdlp_termination_status_t::Optimal, else they
  // would have been returned
  cuopt_assert(termination_current != pdlp_termination_status_t::Optimal,
               "Solution can't be pdlp_termination_status_t::Optimal at this point");
  cuopt_assert(termination_average != pdlp_termination_status_t::Optimal,
               "Solution can't be pdlp_termination_status_t::Optimal at this point");

  // First find best between current and average

  const auto& current_quality = current.get_convergence_information().to_primal_quality_adapter(
    termination_current == pdlp_termination_status_t::PrimalFeasible);
  const auto& average_quality = average.get_convergence_information().to_primal_quality_adapter(
    termination_average == pdlp_termination_status_t::PrimalFeasible);
  const auto& best_candidate = get_best_quality(current_quality, average_quality);

  // Then best between last and best_candidate

  const auto& best_overall = get_best_quality(best_candidate, best_primal_quality_so_far_);

  // Best overall is different (better) than last found
  if (best_overall != best_primal_quality_so_far_) {
#ifdef PDLP_DEBUG_MODE
    RAFT_CUDA_TRY(cudaDeviceSynchronize());
    std::cout << "New best primal found" << std::endl;
#endif
    best_primal_quality_so_far_ = best_overall;

    // Record the new solution

    rmm::device_uvector<f_t>* primal_to_set;
    rmm::device_uvector<f_t>* dual_to_set;
    detail::pdlp_termination_strategy_t<i_t, f_t>* termination_strategy_to_use;
    std::string_view debug_string;

    if (best_overall == current_quality) {
      primal_to_set               = &pdhg_solver_.get_primal_solution();
      dual_to_set                 = &pdhg_solver_.get_dual_solution();
      termination_strategy_to_use = &current_termination_strategy_;
      debug_string                = "  current is better";
    } else {
      primal_to_set               = &unscaled_primal_avg_solution_;
      dual_to_set                 = &unscaled_dual_avg_solution_;
      termination_strategy_to_use = &average_termination_strategy_;
      debug_string                = "  average is better";
    }

#ifdef PDLP_DEBUG_MODE
    RAFT_CUDA_TRY(cudaDeviceSynchronize());
    std::cout << debug_string << std::endl;
#endif

    best_primal_solution_so_far = termination_strategy_to_use->fill_return_problem_solution(
      internal_solver_iterations_,
      pdhg_solver_,
      *primal_to_set,
      *dual_to_set,
      pdlp_termination_status_t::TimeLimit,
      true);
  } else {
#ifdef PDLP_DEBUG_MODE
    RAFT_CUDA_TRY(cudaDeviceSynchronize());
    std::cout << "Last best primal is still best" << std::endl;
#endif
  }
}

template <typename i_t, typename f_t>
pdlp_warm_start_data_t<i_t, f_t> pdlp_solver_t<i_t, f_t>::get_filled_warmed_start_data()
{
  return pdlp_warm_start_data_t<i_t, f_t>(
    pdhg_solver_.get_primal_solution(),
    pdhg_solver_.get_dual_solution(),
    unscaled_primal_avg_solution_,
    unscaled_dual_avg_solution_,
    pdhg_solver_.get_saddle_point_state().get_current_AtY(),
    restart_strategy_.weighted_average_solution_.sum_primal_solutions_,
    restart_strategy_.weighted_average_solution_.sum_dual_solutions_,
    restart_strategy_.last_restart_duality_gap_.primal_solution_,
    restart_strategy_.last_restart_duality_gap_.dual_solution_,
    get_primal_weight_h(),
    get_step_size_h(),
    total_pdlp_iterations_,
    pdhg_solver_.total_pdhg_iterations_,
    restart_strategy_.last_candidate_kkt_score,
    restart_strategy_.last_restart_kkt_score,
    restart_strategy_.weighted_average_solution_.sum_primal_solution_weights_.value(stream_view_),
    restart_strategy_.weighted_average_solution_.iterations_since_last_restart_);
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::print_termination_criteria(const timer_t& timer, bool is_average)
{
  if (!inside_mip_) {
    auto elapsed = timer.elapsed_time();
    if (is_average) {
      average_termination_strategy_.print_termination_criteria(total_pdlp_iterations_, elapsed);
    } else {
      current_termination_strategy_.print_termination_criteria(total_pdlp_iterations_, elapsed);
    }
  }
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::print_final_termination_criteria(
  const timer_t& timer,
  const convergence_information_t<i_t, f_t>& convergence_information,
  const pdlp_termination_status_t& termination_status,
  bool is_average)
{
  if (!inside_mip_) {
    print_termination_criteria(timer, is_average);
    CUOPT_LOG_INFO(
      "LP Solver status:                %s",
      optimization_problem_solution_t<i_t, f_t>::get_termination_status_string(termination_status)
        .c_str());
    CUOPT_LOG_INFO("Primal objective:                %+.8e",
                   convergence_information.get_primal_objective().value(stream_view_));
    CUOPT_LOG_INFO("Dual objective:                  %+.8e",
                   convergence_information.get_dual_objective().value(stream_view_));
    CUOPT_LOG_INFO("Duality gap (abs/rel):           %+.2e / %+.2e",
                   convergence_information.get_gap().value(stream_view_),
                   convergence_information.get_relative_gap_value());
    CUOPT_LOG_INFO("Primal infeasibility (abs/rel):  %+.2e / %+.2e",
                   convergence_information.get_l2_primal_residual().value(stream_view_),
                   convergence_information.get_relative_l2_primal_residual_value());
    CUOPT_LOG_INFO("Dual infeasibility (abs/rel):    %+.2e / %+.2e",
                   convergence_information.get_l2_dual_residual().value(stream_view_),
                   convergence_information.get_relative_l2_dual_residual_value());
  }
}

template <typename i_t, typename f_t>
std::optional<optimization_problem_solution_t<i_t, f_t>> pdlp_solver_t<i_t, f_t>::check_termination(
  const timer_t& timer)
{
  raft::common::nvtx::range fun_scope("Check termination");

  // Still need to always compute the termination condition for current even if we don't check them
  // after for kkt restart
#ifdef PDLP_VERBOSE_MODE
  RAFT_CUDA_TRY(cudaDeviceSynchronize());
  printf("Termination criteria current\n");
  print_termination_criteria(timer, false);
  RAFT_CUDA_TRY(cudaDeviceSynchronize());
#endif
  pdlp_termination_status_t termination_current =
    current_termination_strategy_.evaluate_termination_criteria(
      pdhg_solver_,
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_primal_solution()
        : pdhg_solver_.get_potential_next_primal_solution(),
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_dual_solution()
        : pdhg_solver_.get_potential_next_dual_solution(),
      pdhg_solver_.get_dual_slack(),
      problem_ptr->combined_bounds,
      problem_ptr->objective_coefficients);

#ifdef PDLP_VERBOSE_MODE
  RAFT_CUDA_TRY(cudaDeviceSynchronize());
  std::cout << "Termination criteria average:" << std::endl;
  print_termination_criteria(timer, true);
  RAFT_CUDA_TRY(cudaDeviceSynchronize());
#endif
  // Check both average and current solution
  pdlp_termination_status_t termination_average =
    (pdlp_hyper_params::never_restart_to_average)
      ? pdlp_termination_status_t::NoTermination
      : average_termination_strategy_.evaluate_termination_criteria(
          pdhg_solver_,
          unscaled_primal_avg_solution_,
          unscaled_dual_avg_solution_,
          pdhg_solver_.get_dual_slack(),
          problem_ptr->combined_bounds,
          problem_ptr->objective_coefficients);

  // We exit directly without checking the termination criteria as some problem can have a low
  // initial redidual + there is by definition 0 gap at first
  // To avoid that we allow at least two iterations at first before checking (in practice 0 wasn't
  // enough) We still need to check iteration and time limit prior without breaking the logic below
  // of first checking termination before the limit
  if (total_pdlp_iterations_ <= 1) {
    print_termination_criteria(timer);
    return check_limits(timer);
  }

  // First check for pdlp_termination_reason_t::Optimality and handle the first primal feasible case

  if (settings_.first_primal_feasible) {
    // Both primal feasible, return best objective
    if (termination_average == pdlp_termination_status_t::PrimalFeasible &&
        termination_current == pdlp_termination_status_t::PrimalFeasible) {
      const f_t current_overall_primal_residual =
        current_termination_strategy_.get_convergence_information().get_l2_primal_residual().value(
          stream_view_);
      const f_t average_overall_primal_residual =
        average_termination_strategy_.get_convergence_information().get_l2_primal_residual().value(
          stream_view_);
      if (current_overall_primal_residual < average_overall_primal_residual) {
        return current_termination_strategy_.fill_return_problem_solution(
          internal_solver_iterations_,
          pdhg_solver_,
          (pdlp_hyper_params::use_adaptive_step_size_strategy)
            ? pdhg_solver_.get_primal_solution()
            : pdhg_solver_.get_potential_next_primal_solution(),
          (pdlp_hyper_params::use_adaptive_step_size_strategy)
            ? pdhg_solver_.get_dual_solution()
            : pdhg_solver_.get_potential_next_dual_solution(),
          get_filled_warmed_start_data(),
          termination_current);
      } else  // Average has better overall residual
      {
        return average_termination_strategy_.fill_return_problem_solution(
          internal_solver_iterations_,
          pdhg_solver_,
          unscaled_primal_avg_solution_,
          unscaled_dual_avg_solution_,
          get_filled_warmed_start_data(),
          termination_average);
      }
    } else if (termination_current == pdlp_termination_status_t::PrimalFeasible) {
      return current_termination_strategy_.fill_return_problem_solution(
        internal_solver_iterations_,
        pdhg_solver_,
        (pdlp_hyper_params::use_adaptive_step_size_strategy)
          ? pdhg_solver_.get_primal_solution()
          : pdhg_solver_.get_potential_next_primal_solution(),
        (pdlp_hyper_params::use_adaptive_step_size_strategy)
          ? pdhg_solver_.get_dual_solution()
          : pdhg_solver_.get_potential_next_dual_solution(),
        get_filled_warmed_start_data(),
        termination_current);
    } else if (termination_average == pdlp_termination_status_t::PrimalFeasible) {
      return average_termination_strategy_.fill_return_problem_solution(
        internal_solver_iterations_,
        pdhg_solver_,
        unscaled_primal_avg_solution_,
        unscaled_dual_avg_solution_,
        get_filled_warmed_start_data(),
        termination_average);
    }
    // else neither of the two is primal feasible
  }

  // If both are pdlp_termination_status_t::Optimal, return the one with the lowest KKT score
  if (termination_average == pdlp_termination_status_t::Optimal &&
      termination_current == pdlp_termination_status_t::Optimal) {
    const f_t current_kkt_score = restart_strategy_.compute_kkt_score(
      current_termination_strategy_.get_convergence_information().get_l2_primal_residual(),
      current_termination_strategy_.get_convergence_information().get_l2_dual_residual(),
      current_termination_strategy_.get_convergence_information().get_gap(),
      primal_weight_);

    const f_t average_kkt_score = restart_strategy_.compute_kkt_score(
      average_termination_strategy_.get_convergence_information().get_l2_primal_residual(),
      average_termination_strategy_.get_convergence_information().get_l2_dual_residual(),
      average_termination_strategy_.get_convergence_information().get_gap(),
      primal_weight_);

    if (current_kkt_score < average_kkt_score) {
#ifdef PDLP_VERBOSE_MODE
      std::cout << "Optimal. End total number of iteration current=" << internal_solver_iterations_
                << std::endl;
#endif
      print_final_termination_criteria(
        timer, current_termination_strategy_.get_convergence_information(), termination_current);
      return current_termination_strategy_.fill_return_problem_solution(
        internal_solver_iterations_,
        pdhg_solver_,
        (pdlp_hyper_params::use_adaptive_step_size_strategy)
          ? pdhg_solver_.get_primal_solution()
          : pdhg_solver_.get_potential_next_primal_solution(),
        (pdlp_hyper_params::use_adaptive_step_size_strategy)
          ? pdhg_solver_.get_dual_solution()
          : pdhg_solver_.get_potential_next_dual_solution(),
        get_filled_warmed_start_data(),
        termination_current);
    } else {
#ifdef PDLP_VERBOSE_MODE
      std::cout << "Optimal. End total number of iteration average=" << internal_solver_iterations_
                << std::endl;
#endif
      print_final_termination_criteria(timer,
                                       average_termination_strategy_.get_convergence_information(),
                                       termination_average,
                                       true);
      return average_termination_strategy_.fill_return_problem_solution(
        internal_solver_iterations_,
        pdhg_solver_,
        unscaled_primal_avg_solution_,
        unscaled_dual_avg_solution_,
        get_filled_warmed_start_data(),
        termination_average);
    }
  }

  // If at least one is pdlp_termination_status_t::Optimal, return it
  if (termination_average == pdlp_termination_status_t::Optimal) {
#ifdef PDLP_VERBOSE_MODE
    std::cout << "Optimal. End total number of iteration average=" << internal_solver_iterations_
              << std::endl;
#endif
    print_final_termination_criteria(timer,
                                     average_termination_strategy_.get_convergence_information(),
                                     termination_average,
                                     true);
    return average_termination_strategy_.fill_return_problem_solution(
      internal_solver_iterations_,
      pdhg_solver_,
      unscaled_primal_avg_solution_,
      unscaled_dual_avg_solution_,
      get_filled_warmed_start_data(),
      termination_average);
  }
  if (termination_current == pdlp_termination_status_t::Optimal) {
#ifdef PDLP_VERBOSE_MODE
    std::cout << "Optimal. End total number of iteration current=" << internal_solver_iterations_
              << std::endl;
#endif
    print_final_termination_criteria(
      timer, current_termination_strategy_.get_convergence_information(), termination_current);
    return current_termination_strategy_.fill_return_problem_solution(
      internal_solver_iterations_,
      pdhg_solver_,
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_primal_solution()
        : pdhg_solver_.get_potential_next_primal_solution(),
      (pdlp_hyper_params::use_adaptive_step_size_strategy)
        ? pdhg_solver_.get_dual_solution()
        : pdhg_solver_.get_potential_next_dual_solution(),
      get_filled_warmed_start_data(),
      termination_current);
  }

  // Check for infeasibility

  // If strict infeasibility, any infeasibility is detected, it is returned
  // Else both are needed
  // (If infeasibility_detection is not set, termination reason cannot be Infeasible)
  if (settings_.strict_infeasibility) {
    if (termination_current == pdlp_termination_status_t::PrimalInfeasible ||
        termination_current == pdlp_termination_status_t::DualInfeasible) {
#ifdef PDLP_VERBOSE_MODE
      std::cout << "Current Infeasible. End total number of iteration current="
                << internal_solver_iterations_ << std::endl;
#endif
      print_final_termination_criteria(
        timer, current_termination_strategy_.get_convergence_information(), termination_current);
      return current_termination_strategy_.fill_return_problem_solution(
        internal_solver_iterations_,
        pdhg_solver_,
        (pdlp_hyper_params::use_adaptive_step_size_strategy)
          ? pdhg_solver_.get_primal_solution()
          : pdhg_solver_.get_potential_next_primal_solution(),
        (pdlp_hyper_params::use_adaptive_step_size_strategy)
          ? pdhg_solver_.get_dual_solution()
          : pdhg_solver_.get_potential_next_dual_solution(),
        termination_current);
    }
    if (termination_average == pdlp_termination_status_t::PrimalInfeasible ||
        termination_average == pdlp_termination_status_t::DualInfeasible) {
#ifdef PDLP_VERBOSE_MODE
      std::cout << "Average Infeasible. End total number of iteration current="
                << internal_solver_iterations_ << std::endl;
#endif
      print_final_termination_criteria(timer,
                                       average_termination_strategy_.get_convergence_information(),
                                       termination_average,
                                       true);
      return average_termination_strategy_.fill_return_problem_solution(
        internal_solver_iterations_,
        pdhg_solver_,
        unscaled_primal_avg_solution_,
        unscaled_dual_avg_solution_,
        termination_average);
    }
  } else {
    if ((termination_current == pdlp_termination_status_t::PrimalInfeasible &&
         termination_average == pdlp_termination_status_t::PrimalInfeasible) ||
        (termination_current == pdlp_termination_status_t::DualInfeasible &&
         termination_average == pdlp_termination_status_t::DualInfeasible)) {
#ifdef PDLP_VERBOSE_MODE
      std::cout << "Infeasible. End total number of iteration current="
                << internal_solver_iterations_ << std::endl;
#endif
      print_final_termination_criteria(
        timer, current_termination_strategy_.get_convergence_information(), termination_current);
      return current_termination_strategy_.fill_return_problem_solution(
        internal_solver_iterations_,
        pdhg_solver_,
        (pdlp_hyper_params::use_adaptive_step_size_strategy)
          ? pdhg_solver_.get_primal_solution()
          : pdhg_solver_.get_potential_next_primal_solution(),
        (pdlp_hyper_params::use_adaptive_step_size_strategy)
          ? pdhg_solver_.get_dual_solution()
          : pdhg_solver_.get_potential_next_dual_solution(),
        termination_current);
    }
  }

  // Numerical error has happend (movement is 0 and pdlp_termination_status_t::Optimality has not
  // been reached)
  if (step_size_strategy_.get_valid_step_size() == -1) {
#ifdef PDLP_VERBOSE_MODE
    std::cout << "Numerical Error. End total number of iteration current="
              << internal_solver_iterations_ << std::endl;
#endif
    print_final_termination_criteria(
      timer, current_termination_strategy_.get_convergence_information(), termination_current);
    return optimization_problem_solution_t<i_t, f_t>{pdlp_termination_status_t::NumericalError,
                                                     stream_view_};
  }

  // If not infeasible and not pdlp_termination_status_t::Optimal and no error, record best so far
  // is toggle
  if (settings_.save_best_primal_so_far)
    record_best_primal_so_far(current_termination_strategy_,
                              average_termination_strategy_,
                              termination_current,
                              termination_average);
  if (total_pdlp_iterations_ % 1000 == 0) { print_termination_criteria(timer); }

  // No reason to terminate
  return check_limits(timer);
}

template <typename f_t>
static void compute_stats(const rmm::device_uvector<f_t>& vec,
                          f_t& smallest,
                          f_t& largest,
                          f_t& avg)
{
  auto abs_op      = [] __host__ __device__(f_t x) { return abs(x); };
  auto min_nonzero = [] __host__ __device__(f_t x) {
    return x == 0 ? std::numeric_limits<f_t>::max() : abs(x);
  };

  smallest = thrust::transform_reduce(rmm::exec_policy(vec.stream()),
                                      vec.begin(),
                                      vec.end(),
                                      min_nonzero,
                                      std::numeric_limits<f_t>::max(),
                                      thrust::minimum<f_t>());

  largest = thrust::transform_reduce(
    rmm::exec_policy(vec.stream()), vec.begin(), vec.end(), abs_op, 0.0f, thrust::maximum<f_t>());

  f_t sum = thrust::transform_reduce(
    rmm::exec_policy(vec.stream()), vec.begin(), vec.end(), abs_op, 0.0f, thrust::plus<f_t>());

  avg = sum / vec.size();
};

template <typename f_t>
static void print_problem_info(const rmm::device_uvector<f_t>& nonzero_coeffs,
                               const rmm::device_uvector<f_t>& objective_coeffs,
                               const rmm::device_uvector<f_t>& combined_bounds)
{
  RAFT_CUDA_TRY(cudaDeviceSynchronize());

  // Get stats for constraint matrix coefficients
  f_t smallest, largest, avg;
  compute_stats(nonzero_coeffs, smallest, largest, avg);
  std::cout << "Absolute value of nonzero constraint matrix elements: largest=" << largest
            << ", smallest=" << smallest << ", avg=" << avg << std::endl;

  // Get stats for objective coefficients
  compute_stats(objective_coeffs, smallest, largest, avg);
  std::cout << "Absolute value of objective vector elements: largest=" << largest
            << ", smallest=" << smallest << ", avg=" << avg << std::endl;

  // Get stats for combined bounds
  compute_stats(combined_bounds, smallest, largest, avg);
  std::cout << "Absolute value of rhs vector elements: largest=" << largest
            << ", smallest=" << smallest << ", avg=" << avg << std::endl;

  RAFT_CUDA_TRY(cudaDeviceSynchronize());
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::update_primal_dual_solutions(
  std::optional<const rmm::device_uvector<f_t>*> primal,
  std::optional<const rmm::device_uvector<f_t>*> dual)
{
#ifdef PDLP_DEBUG_MODE
  std::cout << "  Updating primal and dual solution" << std::endl;
#endif

  // Copy the initial solution in pdhg as a first solution
  if (primal) {
    raft::copy(pdhg_solver_.get_primal_solution().data(),
               primal.value()->data(),
               primal_size_h_,
               stream_view_);
  }
  if (dual) {
    raft::copy(
      pdhg_solver_.get_dual_solution().data(), dual.value()->data(), dual_size_h_, stream_view_);
  }

  // Handle initial step size if needed

  if (pdlp_hyper_params::update_step_size_on_initial_solution) {
#ifdef PDLP_DEBUG_MODE
    std::cout << "    Updating initial step size on initial solution" << std::endl;
#endif

    // Computing a new step size only make sense if both are set and not all 0
    const bool both_initial_set = primal && dual;
    const bool primal_not_all_zeros =
      both_initial_set && thrust::count(handle_ptr_->get_thrust_policy(),
                                        primal.value()->begin(),
                                        primal.value()->end(),
                                        f_t(0)) != static_cast<i_t>(primal.value()->size());
    const bool dual_not_all_zeros =
      both_initial_set && thrust::count(handle_ptr_->get_thrust_policy(),
                                        dual.value()->begin(),
                                        dual.value()->end(),
                                        f_t(0)) != static_cast<i_t>(dual.value()->size());

    if (both_initial_set && primal_not_all_zeros && dual_not_all_zeros) {
      // To compute an initial step size we use adaptative_step_size.compute_step_sizes
      // It requieres setting potential_next_dual_solution, current_Aty and both delta primal and
      // dual Since we want to mimick a movement from an all 0 solutions, we can simply set both
      // potential_next_dual_solution and our delta to our initial solution current_Aty to all 0

      auto& saddle = pdhg_solver_.get_saddle_point_state();

      // Set all 4 fields
      raft::copy(saddle.get_delta_primal().data(),
                 primal.value()->data(),
                 saddle.get_delta_primal().size(),
                 stream_view_);
      raft::copy(saddle.get_delta_dual().data(),
                 dual.value()->data(),
                 saddle.get_delta_dual().size(),
                 stream_view_);
      raft::copy(pdhg_solver_.get_potential_next_dual_solution().data(),
                 dual.value()->data(),
                 pdhg_solver_.get_potential_next_dual_solution().size(),
                 stream_view_);
      RAFT_CUDA_TRY(cudaMemsetAsync(saddle.get_current_AtY().data(),
                                    f_t(0.0),
                                    sizeof(f_t) * saddle.get_current_AtY().size(),
                                    stream_view_));

      // Scale if should compute initial step size after scaling
      if (!pdlp_hyper_params::compute_initial_step_size_before_scaling) {
#ifdef PDLP_DEBUG_MODE
        std::cout << "      Scaling before computing initial step size" << std::endl;
#endif
        initial_scaling_strategy_.scale_solutions(saddle.get_delta_primal(),
                                                  saddle.get_delta_dual());
        initial_scaling_strategy_.scale_dual(pdhg_solver_.get_potential_next_dual_solution());
      }

      // Compute an initial step size
      ++pdhg_solver_.total_pdhg_iterations_;  // Fake a first initial PDHG step, else it will break
                                              // the computation
      step_size_strategy_.compute_step_sizes(pdhg_solver_, primal_step_size_, dual_step_size_, 0);
      --pdhg_solver_.total_pdhg_iterations_;

      // Else scale after computing initial step size
      if (pdlp_hyper_params::compute_initial_step_size_before_scaling) {
#ifdef PDLP_DEBUG_MODE
        std::cout << "      Scaling after computing initial step size" << std::endl;
#endif
        initial_scaling_strategy_.scale_solutions(saddle.get_delta_primal(),
                                                  saddle.get_delta_dual());
        initial_scaling_strategy_.scale_dual(pdhg_solver_.get_potential_next_dual_solution());
      }
    }
  }

  // Handle initial primal weight if needed

  // We should always scale the initial solution
  // We scale here only if it is not done after if
  // compute_initial_primal_weight_before_scaling is true

  // Scale if should compute primal weight after scaling
  if (!pdlp_hyper_params::compute_initial_primal_weight_before_scaling) {
#ifdef PDLP_DEBUG_MODE
    std::cout << "      Scaling before computing initial primal weight:" << std::endl;
#endif
    initial_scaling_strategy_.scale_solutions(pdhg_solver_.get_primal_solution(),
                                              pdhg_solver_.get_dual_solution());
  }

  // If only primal or dual is set, the primal weight wont (as it can't) be updated
  if (pdlp_hyper_params::update_primal_weight_on_initial_solution) {
#ifdef PDLP_DEBUG_MODE
    std::cout << "      Updating the initial primal weight on initial solution" << std::endl;
#endif
    restart_strategy_.update_distance(
      pdhg_solver_, primal_weight_, primal_step_size_, dual_step_size_, step_size_);
  }

  // We scale here because it was not done previously
  if (pdlp_hyper_params::compute_initial_primal_weight_before_scaling) {
    initial_scaling_strategy_.scale_solutions(pdhg_solver_.get_primal_solution(),
                                              pdhg_solver_.get_dual_solution());
  }
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::compute_fixed_error(bool& has_restarted)
{
#ifdef CUPDLP_DEBUG_MODE
  printf("Computing compute_fixed_point_error \n");
#endif
  cuopt_assert(pdhg_solver_.get_reflected_primal().size() == primal_size_h_,
               "reflected_primal_ size mismatch");
  cuopt_assert(pdhg_solver_.get_reflected_dual().size() == dual_size_h_,
               "reflected_dual_ size mismatch");
  cuopt_assert(pdhg_solver_.get_primal_solution().size() == primal_size_h_,
               "primal_solution_ size mismatch");
  cuopt_assert(pdhg_solver_.get_dual_solution().size() == dual_size_h_,
               "dual_solution_ size mismatch");
  cuopt_assert(pdhg_solver_.get_saddle_point_state().get_delta_primal().size() == primal_size_h_,
               "delta_primal_ size mismatch");
  cuopt_assert(pdhg_solver_.get_saddle_point_state().get_delta_dual().size() == dual_size_h_,
               "delta_dual_ size mismatch");

  // Computing the deltas
  cub::DeviceTransform::Transform(cuda::std::make_tuple(pdhg_solver_.get_reflected_primal().data(),
                                                        pdhg_solver_.get_primal_solution().data()),
                                  pdhg_solver_.get_saddle_point_state().get_delta_primal().data(),
                                  primal_size_h_,
                                  cuda::std::minus<f_t>{},
                                  stream_view_);
  cub::DeviceTransform::Transform(cuda::std::make_tuple(pdhg_solver_.get_reflected_dual().data(),
                                                        pdhg_solver_.get_dual_solution().data()),
                                  pdhg_solver_.get_saddle_point_state().get_delta_dual().data(),
                                  dual_size_h_,
                                  cuda::std::minus<f_t>{},
                                  stream_view_);

  auto& cusparse_view = pdhg_solver_.get_cusparse_view();
  // Make potential_next_dual_solution point towards reflected dual solution to reuse the code
  RAFT_CUSPARSE_TRY(cusparseDnVecSetValues(cusparse_view.potential_next_dual_solution,
                                           (void*)pdhg_solver_.get_reflected_dual().data()));

  step_size_strategy_.compute_interaction_and_movement(
    pdhg_solver_.get_primal_tmp_resource(), cusparse_view, pdhg_solver_.get_saddle_point_state());

  const f_t movement =
    step_size_strategy_.get_norm_squared_delta_primal() * primal_weight_.value(stream_view_) +
    step_size_strategy_.get_norm_squared_delta_dual() / primal_weight_.value(stream_view_);
  const f_t interaction =
    f_t(2.0) * step_size_strategy_.get_interaction() * step_size_.value(stream_view_);

  restart_strategy_.fixed_point_error_ = std::sqrt(movement + interaction);

#ifdef CUPDLP_DEBUG_MODE
  printf("movement %lf\n", movement);
  printf("interaction %lf\n", interaction);
  printf("state->fixed_point_error %lf\n", restart_strategy_.fixed_point_error_);
#endif

  // Put back
  RAFT_CUSPARSE_TRY(
    cusparseDnVecSetValues(cusparse_view.potential_next_dual_solution,
                           (void*)pdhg_solver_.get_potential_next_dual_solution().data()));

  if (has_restarted) {
    restart_strategy_.initial_fixed_point_error_ = restart_strategy_.fixed_point_error_;
    has_restarted                                = false;
  }
}

template <typename i_t, typename f_t>
optimization_problem_solution_t<i_t, f_t> pdlp_solver_t<i_t, f_t>::run_solver(const timer_t& timer)
{
  bool verbose;
#ifdef PDLP_VERBOSE_MODE
  verbose = true;
#else
  verbose = false;
#endif

#ifdef PDLP_DEBUG_MODE
  std::cout << "Starting PDLP loop:" << std::endl;
#endif

  if (pdlp_hyper_params::compute_initial_step_size_before_scaling) compute_initial_step_size();
  if (pdlp_hyper_params::compute_initial_primal_weight_before_scaling)
    compute_initial_primal_weight();

  initial_scaling_strategy_.scale_problem();

  if (!pdlp_hyper_params::compute_initial_step_size_before_scaling) compute_initial_step_size();
  if (!pdlp_hyper_params::compute_initial_primal_weight_before_scaling)
    compute_initial_primal_weight();

#ifdef PDLP_DEBUG_MODE
  std::cout << "Initial Scaling done" << std::endl;
#endif

  // Needs to be performed here before the below line to make sure the initial primal_weight / step
  // size are used as previous point when potentially updating them in this next call
  if (initial_step_size_.has_value())
    step_size_.set_value_async(initial_step_size_.value(), stream_view_);
  if (initial_primal_weight_.has_value())
    primal_weight_.set_value_async(initial_primal_weight_.value(), stream_view_);
  if (initial_k_.has_value()) {
    pdhg_solver_.total_pdhg_iterations_ = initial_k_.value();
    pdhg_solver_.get_d_total_pdhg_iterations().set_value_async(initial_k_.value(), stream_view_);
  }

  // Only the primal_weight_ and step_size_ variables are initialized during the initial phase
  // The associated primal/dual step_size (computed using the two firstly mentionned) are not
  // initialized. This calls ensures the latter
  // In the event of a given primal and dual solutions and if the option is toggled, calling the
  // update primal_weight and step_size will also update the associated primal_step_size_,
  // dual_step_size_. In summary: the below call is only mandatory at the beginning when
  // computing/setting the initial primal weight and step size and if they are not recomputed later.
  step_size_strategy_.get_primal_and_dual_stepsizes(primal_step_size_, dual_step_size_);

  // If there is an initial primal or dual we should update the restart info as if there was a step
  // that has happend
  if (initial_primal_.size() != 0 || initial_dual_.size() != 0) {
    update_primal_dual_solutions(
      (initial_primal_.size() != 0) ? std::make_optional(&initial_primal_) : std::nullopt,
      (initial_dual_.size() != 0) ? std::make_optional(&initial_dual_) : std::nullopt);
  }

  // Project initial primal solution
  if (pdlp_hyper_params::project_initial_primal) {
    using f_t2 = typename type_2<f_t>::type;
    cub::DeviceTransform::Transform(
      cuda::std::make_tuple(pdhg_solver_.get_primal_solution().data(),
                            op_problem_scaled_.variable_bounds.data()),
      pdhg_solver_.get_primal_solution().data(),
      primal_size_h_,
      clamp<f_t, f_t2>(),
      stream_view_);
    cub::DeviceTransform::Transform(
      cuda::std::make_tuple(unscaled_primal_avg_solution_.data(),
                            op_problem_scaled_.variable_bounds.data()),
      unscaled_primal_avg_solution_.data(),
      primal_size_h_,
      clamp<f_t, f_t2>(),
      stream_view_);
  }

  if (verbose) {
    std::cout << "primal_size_h_ " << primal_size_h_ << " dual_size_h_ " << dual_size_h_ << " nnz "
              << problem_ptr->nnz << std::endl;
    std::cout << "Problem before scaling" << std::endl;
    print_problem_info<f_t>(
      problem_ptr->coefficients, problem_ptr->objective_coefficients, problem_ptr->combined_bounds);
    std::cout << "Problem after scaling" << std::endl;
    print_problem_info<f_t>(op_problem_scaled_.coefficients,
                            op_problem_scaled_.objective_coefficients,
                            op_problem_scaled_.combined_bounds);
    raft::print_device_vector("Initial step_size", step_size_.data(), 1, std::cout);
    raft::print_device_vector("Initial primal_weight", primal_weight_.data(), 1, std::cout);
    raft::print_device_vector("Initial primal_step_size", primal_step_size_.data(), 1, std::cout);
    raft::print_device_vector("Initial dual_step_size", dual_step_size_.data(), 1, std::cout);
  }
#ifdef CUPDLP_DEBUG_MODE
  printf("Initial primal weight %lf, step size %lf\n",
         primal_weight_.value(stream_view_),
         step_size_.value(stream_view_));
#endif

  bool warm_start_was_given =
    settings_.get_pdlp_warm_start_data().last_restart_duality_gap_dual_solution_.size() != 0;

  if (!inside_mip_) {
    CUOPT_LOG_INFO(
      "   Iter    Primal Obj.      Dual Obj.    Gap        Primal Res.  Dual Res.   Time");
  }
  while (true) {
#ifdef CUPDLP_DEBUG_MODE
    printf("Step: %d\n", total_pdlp_iterations_);
#endif
    bool is_major_iteration =
      (((total_pdlp_iterations_) % pdlp_hyper_params::major_iteration == 0) &&
       (total_pdlp_iterations_ > 0)) ||
      (total_pdlp_iterations_ <= pdlp_hyper_params::min_iteration_restart);
    bool error_occured                      = (step_size_strategy_.get_valid_step_size() == -1);
    bool artificial_restart_check_main_loop = false;
    bool has_restarted                      = false;
    bool is_conditional_major =
      (pdlp_hyper_params::use_conditional_major)
        ? (total_pdlp_iterations_ % conditional_major<i_t>(total_pdlp_iterations_)) == 0
        : false;
    if (pdlp_hyper_params::artificial_restart_in_main_loop)
      artificial_restart_check_main_loop =
        restart_strategy_.should_do_artificial_restart(total_pdlp_iterations_);
    if (is_major_iteration || artificial_restart_check_main_loop || error_occured ||
        is_conditional_major) {
      if (verbose) {
        std::cout << "-------------------------------" << std::endl;
        std::cout << internal_solver_iterations_ << std::endl;
        raft::print_device_vector("step_size", step_size_.data(), 1, std::cout);
        raft::print_device_vector("primal_weight", primal_weight_.data(), 1, std::cout);
        raft::print_device_vector("primal_step_size", primal_step_size_.data(), 1, std::cout);
        raft::print_device_vector("dual_step_size", dual_step_size_.data(), 1, std::cout);
      }

      // If a warm start is given and it's the first step, the average solutions were already filled
      bool no_rescale_average = internal_solver_iterations_ == 0 && warm_start_was_given;

      if (!no_rescale_average) {
        // Average in PDLP is scaled then unscaled which can create numerical innacuracies (a * x /
        // x can != x using float) This can create issues when comparing current and average kkt
        // scores, falsly assuming they are different while they should be equal They should be
        // equal:
        // 1. At the very beginning of the solver, when no steps have been taken yet
        // 2. After a single step, since average of one step is the same step
        if (internal_solver_iterations_ <= 1) {
          raft::copy(unscaled_primal_avg_solution_.data(),
                     pdhg_solver_.get_primal_solution().data(),
                     primal_size_h_,
                     stream_view_);
          raft::copy(unscaled_dual_avg_solution_.data(),
                     pdhg_solver_.get_dual_solution().data(),
                     dual_size_h_,
                     stream_view_);
        } else {
          restart_strategy_.get_average_solutions(unscaled_primal_avg_solution_,
                                                  unscaled_dual_avg_solution_);
        }
      }

      // We go back to the unscaled problem here. It ensures that we do not terminate 'too early'
      // because of the error margin being evaluated on the scaled problem

      // Evaluation is done on the unscaled problem and solutions

      // If warm start data was given, the average solutions were also already scaled
      if (!no_rescale_average) {
        initial_scaling_strategy_.unscale_solutions(unscaled_primal_avg_solution_,
                                                    unscaled_dual_avg_solution_);
      }
      if (pdlp_hyper_params::use_adaptive_step_size_strategy) {
        initial_scaling_strategy_.unscale_solutions(pdhg_solver_.get_primal_solution(),
                                                    pdhg_solver_.get_dual_solution());
      } else {
        initial_scaling_strategy_.unscale_solutions(
          pdhg_solver_.get_potential_next_primal_solution(),
          pdhg_solver_.get_potential_next_dual_solution(),
          pdhg_solver_.get_dual_slack());
      }

      // Check for termination
      std::optional<optimization_problem_solution_t<i_t, f_t>> solution = check_termination(timer);

      if (solution.has_value()) { return std::move(solution.value()); }

      if (pdlp_hyper_params::rescale_for_restart) {
        initial_scaling_strategy_.scale_solutions(unscaled_primal_avg_solution_,
                                                  unscaled_dual_avg_solution_);
        if (pdlp_hyper_params::use_adaptive_step_size_strategy) {
          initial_scaling_strategy_.scale_solutions(pdhg_solver_.get_primal_solution(),
                                                    pdhg_solver_.get_dual_solution());
        } else {
          initial_scaling_strategy_.scale_solutions(
            pdhg_solver_.get_potential_next_primal_solution(),
            pdhg_solver_.get_potential_next_dual_solution(),
            pdhg_solver_.get_dual_slack());
        }
      }

      if (pdlp_hyper_params::restart_strategy !=
            static_cast<int>(
              detail::pdlp_restart_strategy_t<i_t, f_t>::restart_strategy_t::NO_RESTART) &&
          (is_major_iteration || artificial_restart_check_main_loop)) {
        has_restarted = restart_strategy_.compute_restart(
          pdhg_solver_,
          unscaled_primal_avg_solution_,
          unscaled_dual_avg_solution_,
          total_pdlp_iterations_,
          primal_step_size_,
          dual_step_size_,
          primal_weight_,
          step_size_,
          current_termination_strategy_.get_convergence_information(),  // Needed for KKT restart
          average_termination_strategy_.get_convergence_information(),  // Needed for KKT restart
          best_primal_weight_  // Needed for cuPDLP+ restart
        );
      }

      if (!pdlp_hyper_params::rescale_for_restart) {
        // We don't need to rescale average because what matters is weighted_average_solution
        // getting the scaled accumulation
        // During the next iteration, unscaled_avg_solution will be overwritten again through
        // get_average_solutions
        if (pdlp_hyper_params::use_adaptive_step_size_strategy) {
          initial_scaling_strategy_.scale_solutions(pdhg_solver_.get_primal_solution(),
                                                    pdhg_solver_.get_dual_solution());
        } else {
          initial_scaling_strategy_.scale_solutions(
            pdhg_solver_.get_potential_next_primal_solution(),
            pdhg_solver_.get_potential_next_dual_solution(),
            pdhg_solver_.get_dual_slack());
        }
      }
    }

#ifdef CUPDLP_DEBUG_MODE
    printf("Is Major %d\n", (total_pdlp_iterations_ + 1) % pdlp_hyper_params::major_iteration == 0);
#endif
    take_step(total_pdlp_iterations_,
              (total_pdlp_iterations_ + 1) % pdlp_hyper_params::major_iteration == 0);

    if (pdlp_hyper_params::use_reflected_primal_dual) {
      if (pdlp_hyper_params::use_fixed_point_error &&
            (total_pdlp_iterations_ + 1) % pdlp_hyper_params::major_iteration == 0 ||
          has_restarted)
        compute_fixed_error(has_restarted);  // May set has_restarted to false

      halpern_update();
    }

    ++total_pdlp_iterations_;
    ++internal_solver_iterations_;
    if (pdlp_hyper_params::never_restart_to_average)
      restart_strategy_.increment_iteration_since_last_restart();
  }
  return optimization_problem_solution_t<i_t, f_t>{pdlp_termination_status_t::NumericalError,
                                                   stream_view_};
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::take_adaptive_step(i_t total_pdlp_iterations, bool is_major_iteration)
{
  // continue testing stepsize until we find a valid one or encounter a numerical error
  step_size_strategy_.set_valid_step_size(0);

  while (step_size_strategy_.get_valid_step_size() == 0) {
#ifdef PDLP_DEBUG_MODE
    std::cout << "PDHG Iteration:\n"
              << "    primal_weight=" << primal_weight_.value(stream_view_) << "\n"
              << "    step_size=" << step_size_.value(stream_view_) << "\n"
              << "    primal_step_size=" << primal_step_size_.value(stream_view_) << "\n"
              << "    dual_step_size=" << dual_step_size_.value(stream_view_) << std::endl;
#endif
    pdhg_solver_.take_step(primal_step_size_,
                           dual_step_size_,
                           restart_strategy_.get_iterations_since_last_restart(),
                           restart_strategy_.get_last_restart_was_average(),
                           total_pdlp_iterations,
                           is_major_iteration);

    step_size_strategy_.compute_step_sizes(
      pdhg_solver_, primal_step_size_, dual_step_size_, total_pdlp_iterations);
  }
#ifdef PDLP_DEBUG_MODE
  std::cout << "PDHG Iteration: valid step size found" << std::endl;
#endif

  // Valid state found, update internal solution state
  // Average is being added asynchronously on the GPU while the solution is being updated on the CPU
  restart_strategy_.add_current_solution_to_average_solution(
    pdhg_solver_.get_potential_next_primal_solution().data(),
    pdhg_solver_.get_potential_next_dual_solution().data(),
    step_size_,
    total_pdlp_iterations);
  pdhg_solver_.update_solution(current_op_problem_evaluation_cusparse_view_);
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::take_constant_step(bool is_major_iteration)
{
  pdhg_solver_.take_step(
    primal_step_size_, dual_step_size_, 0, false, total_pdlp_iterations_, is_major_iteration);
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::halpern_update()
{
  raft::common::nvtx::range fun_scope("halpern_update");

  const f_t weight =
    f_t(restart_strategy_.weighted_average_solution_.get_iterations_since_last_restart() + 1) /
    f_t(restart_strategy_.weighted_average_solution_.get_iterations_since_last_restart() + 2);

#ifdef CUPDLP_DEBUG_MODE
  printf("halper_update weight %lf\n", weight);
#endif

  // Update primal
  cub::DeviceTransform::Transform(
    cuda::std::make_tuple(pdhg_solver_.get_reflected_primal().data(),
                          pdhg_solver_.get_saddle_point_state().get_primal_solution().data(),
                          restart_strategy_.last_restart_duality_gap_.primal_solution_.data()),
    pdhg_solver_.get_saddle_point_state().get_primal_solution().data(),
    primal_size_h_,
    [weight, reflection_coefficient = pdlp_hyper_params::reflection_coefficient] __device__(
      f_t reflected_primal, f_t current_primal, f_t initial_primal) {
      const f_t reflected = reflection_coefficient * reflected_primal +
                            (f_t(1.0) - reflection_coefficient) * current_primal;
      return weight * reflected + (f_t(1.0) - weight) * initial_primal;
    },
    stream_view_);

  // Update dual
  cub::DeviceTransform::Transform(
    cuda::std::make_tuple(pdhg_solver_.get_reflected_dual().data(),
                          pdhg_solver_.get_saddle_point_state().get_dual_solution().data(),
                          restart_strategy_.last_restart_duality_gap_.dual_solution_.data()),
    pdhg_solver_.get_saddle_point_state().get_dual_solution().data(),
    dual_size_h_,
    [weight, reflection_coefficient = pdlp_hyper_params::reflection_coefficient] __device__(
      f_t reflected_dual, f_t current_dual, f_t initial_dual) {
      const f_t reflected = reflection_coefficient * reflected_dual +
                            (f_t(1.0) - reflection_coefficient) * current_dual;
      return weight * reflected + (f_t(1.0) - weight) * initial_dual;
    },
    stream_view_);

#ifdef CUPDLP_DEBUG_MODE
  print("halpen_update current primal",
        pdhg_solver_.get_saddle_point_state().get_primal_solution());
  print("halpen_update current dual", pdhg_solver_.get_saddle_point_state().get_dual_solution());
#endif
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::take_step([[maybe_unused]] i_t total_pdlp_iterations,
                                        [[maybe_unused]] bool is_major_iteration)
{
  if (pdlp_hyper_params::use_adaptive_step_size_strategy) {
    take_adaptive_step(total_pdlp_iterations, is_major_iteration);
  } else {
    cuopt_assert(total_pdlp_iterations == pdhg_solver_.get_total_pdhg_iterations(),
                 "In non adaptive step size mode, both pdlp and pdhg step should always be equal");
    take_constant_step(is_major_iteration);
  }
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::compute_initial_step_size()
{
  raft::common::nvtx::range fun_scope("compute_initial_step_size");

  if (!pdlp_hyper_params::initial_step_size_max_singular_value) {
    // set stepsize relative to maximum absolute value of A
    rmm::device_scalar<f_t> abs_max_element{0.0, stream_view_};
    void* d_temp_storage      = NULL;
    size_t temp_storage_bytes = 0;

    detail::max_abs_value<f_t> red_op;
    cub::DeviceReduce::Reduce(d_temp_storage,
                              temp_storage_bytes,
                              op_problem_scaled_.coefficients.data(),
                              abs_max_element.data(),
                              op_problem_scaled_.nnz,
                              red_op,
                              0.0,
                              stream_view_);
    // Allocate temporary storage
    rmm::device_buffer cub_tmp{temp_storage_bytes, stream_view_};
    // Run max-reduction
    cub::DeviceReduce::Reduce(cub_tmp.data(),
                              temp_storage_bytes,
                              op_problem_scaled_.coefficients.data(),
                              abs_max_element.data(),
                              op_problem_scaled_.nnz,
                              red_op,
                              0.0,
                              stream_view_);
    raft::linalg::eltwiseDivideCheckZero(
      step_size_.data(), step_size_.data(), abs_max_element.data(), 1, stream_view_);

    // Sync since we are using local variable
    RAFT_CUDA_TRY(cudaStreamSynchronize(stream_view_));
  } else {
    constexpr i_t max_iterations = 5000;
    constexpr f_t tolerance      = 1e-4;

    i_t m = op_problem_scaled_.n_constraints;
    i_t n = op_problem_scaled_.n_variables;

    std::vector<f_t> z(m);
    rmm::device_uvector<f_t> d_z(m, stream_view_);
    rmm::device_uvector<f_t> d_q(m, stream_view_);
    rmm::device_uvector<f_t> d_atq(n, stream_view_);

    std::mt19937 gen(1);
    std::normal_distribution<double> dist(0.0, 1.0);

    for (int i = 0; i < m; ++i)
      z[i] = dist(gen);

    device_copy(d_z, z, stream_view_);

    rmm::device_scalar<f_t> norm_q(stream_view_);
    rmm::device_scalar<f_t> sigma_max_sq(stream_view_);
    rmm::device_scalar<f_t> residual_norm(stream_view_);
    rmm::device_scalar<f_t> reusable_device_scalar_value_1_(1, stream_view_);
    rmm::device_scalar<f_t> reusable_device_scalar_value_0_(0, stream_view_);

    cusparseDnVecDescr_t vecZ, vecQ, vecATQ;
    RAFT_CUSPARSE_TRY(
      raft::sparse::detail::cusparsecreatednvec(&vecZ, m, const_cast<f_t*>(d_z.data())));
    RAFT_CUSPARSE_TRY(
      raft::sparse::detail::cusparsecreatednvec(&vecQ, m, const_cast<f_t*>(d_q.data())));
    RAFT_CUSPARSE_TRY(
      raft::sparse::detail::cusparsecreatednvec(&vecATQ, n, const_cast<f_t*>(d_atq.data())));

    const auto& cusparse_view_ = pdhg_solver_.get_cusparse_view();

    int sing_iters = 0;
    for (int i = 0; i < max_iterations; ++i) {
      ++sing_iters;
      // d_q = d_z
      raft::copy(d_q.data(), d_z.data(), m, stream_view_);
      // norm_q = l2_norm(d_q)
      my_l2_norm<i_t, f_t>(d_q, norm_q, handle_ptr_);

      cuopt_assert(norm_q.value(stream_view_) != f_t(0), "norm q can't be 0");

      // d_q *= 1 / norm_q
      cub::DeviceTransform::Transform(
        d_q.data(),
        d_q.data(),
        d_q.size(),
        [norm_q = norm_q.data()] __device__(f_t d_q) { return d_q / *norm_q; },
        stream_view_);

      // A_t_q = A_t @ d_q
      RAFT_CUSPARSE_TRY(
        raft::sparse::detail::cusparsespmv(handle_ptr_->get_cusparse_handle(),
                                           CUSPARSE_OPERATION_NON_TRANSPOSE,
                                           reusable_device_scalar_value_1_.data(),
                                           cusparse_view_.A_T,
                                           vecQ,
                                           reusable_device_scalar_value_0_.data(),
                                           vecATQ,
                                           CUSPARSE_SPMV_CSR_ALG2,
                                           (f_t*)cusparse_view_.buffer_transpose.data(),
                                           stream_view_));

      // z = A @ A_t_q
      RAFT_CUSPARSE_TRY(
        raft::sparse::detail::cusparsespmv(handle_ptr_->get_cusparse_handle(),
                                           CUSPARSE_OPERATION_NON_TRANSPOSE,
                                           reusable_device_scalar_value_1_.data(),  // 1
                                           cusparse_view_.A,
                                           vecATQ,
                                           reusable_device_scalar_value_0_.data(),  // 1
                                           vecZ,
                                           CUSPARSE_SPMV_CSR_ALG2,
                                           (f_t*)cusparse_view_.buffer_non_transpose.data(),
                                           stream_view_));
      // sigma_max_sq = dot(q, z)
      RAFT_CUBLAS_TRY(raft::linalg::detail::cublasdot(handle_ptr_->get_cublas_handle(),
                                                      m,
                                                      d_q.data(),
                                                      primal_stride,
                                                      d_z.data(),
                                                      primal_stride,
                                                      sigma_max_sq.data(),
                                                      stream_view_));

      cub::DeviceTransform::Transform(
        cuda::std::make_tuple(d_q.data(), d_z.data()),
        d_q.data(),
        d_q.size(),
        [sigma_max_sq = sigma_max_sq.data()] __device__(f_t d_q, f_t d_z) {
          return d_q * -(*sigma_max_sq) + d_z;
        },
        stream_view_);

      my_l2_norm<i_t, f_t>(d_q, residual_norm, handle_ptr_);

      if (residual_norm.value(stream_view_) < tolerance) break;
    }
#ifdef CUPDLP_DEBUG_MODE
    printf("iter_count %d\n", sing_iters);
#endif

    constexpr f_t scaling_factor = 0.998;
    const f_t step_size          = scaling_factor / std::sqrt(sigma_max_sq.value(stream_view_));
    step_size_.set_value_async(step_size, stream_view_);

    // Sync since we are using local variable
    RAFT_CUDA_TRY(cudaStreamSynchronize(stream_view_));
    RAFT_CUSPARSE_TRY(cusparseDestroyDnVec(vecZ));
    RAFT_CUSPARSE_TRY(cusparseDestroyDnVec(vecQ));
    RAFT_CUSPARSE_TRY(cusparseDestroyDnVec(vecATQ));
  }
}

template <typename f_t>
__global__ void compute_weights_initial_primal_weight_from_squared_norms(const f_t* b_vec_norm,
                                                                         const f_t* c_vec_norm,
                                                                         f_t* primal_weight,
                                                                         f_t* best_primal_weight)
{
  if (threadIdx.x + blockIdx.x * blockDim.x > 0) { return; }
  f_t c_vec_norm_ = *c_vec_norm;
  f_t b_vec_norm_ = *b_vec_norm;

  if (b_vec_norm_ > 0.0 && c_vec_norm_ > 0.0) {
#ifdef PDLP_DEBUG_MODE
    printf("b_vec_norm_ %lf c_vec_norm_ %lf primal_importance %lf\n",
           b_vec_norm_,
           c_vec_norm_,
           pdlp_hyper_params::primal_importance);
#endif
    *primal_weight      = pdlp_hyper_params::primal_importance * (c_vec_norm_ / b_vec_norm_);
    *best_primal_weight = *primal_weight;
  } else {
    *primal_weight      = pdlp_hyper_params::primal_importance;
    *best_primal_weight = *primal_weight;
  }
}

template <typename i_t, typename f_t>
void pdlp_solver_t<i_t, f_t>::compute_initial_primal_weight()
{
  raft::common::nvtx::range fun_scope("compute_initial_primal_weight");

  // Here we use the combined bounds of the op_problem_scaled which may or may not be scaled yet
  // based on pdlp config
  detail::combine_constraint_bounds<i_t, f_t>(op_problem_scaled_,
                                              op_problem_scaled_.combined_bounds);
  rmm::device_scalar<f_t> c_vec_norm{0.0, stream_view_};
  detail::my_l2_weighted_norm<i_t, f_t>(op_problem_scaled_.objective_coefficients,
                                        pdlp_hyper_params::initial_primal_weight_c_scaling,
                                        c_vec_norm,
                                        stream_view_);

  rmm::device_scalar<f_t> b_vec_norm{0.0, stream_view_};
  if (pdlp_hyper_params::initial_primal_weight_combined_bounds) {
    // => same as sqrt(dot(b,b))
    detail::my_l2_weighted_norm<i_t, f_t>(op_problem_scaled_.combined_bounds,
                                          pdlp_hyper_params::initial_primal_weight_b_scaling,
                                          b_vec_norm,
                                          stream_view_);

  } else {
    if (pdlp_hyper_params::bound_objective_rescaling) {
      const f_t one = 1;
      primal_weight_.set_value_async(one, stream_view_);
      best_primal_weight_.set_value_async(one, stream_view_);
      return;
    } else {
      cuopt_expects(pdlp_hyper_params::initial_primal_weight_b_scaling == 1,
                    error_type_t::ValidationError,
                    "Passing a scaling is not supported for now");

      compute_sum_bounds(op_problem_scaled_.constraint_lower_bounds,
                         op_problem_scaled_.constraint_upper_bounds,
                         b_vec_norm,
                         stream_view_);
    }
  }

  compute_weights_initial_primal_weight_from_squared_norms<<<1, 1, 0, stream_view_>>>(
    b_vec_norm.data(), c_vec_norm.data(), primal_weight_.data(), best_primal_weight_.data());
  RAFT_CUDA_TRY(cudaPeekAtLastError());

  // Sync since we are using local variable
  RAFT_CUDA_TRY(cudaStreamSynchronize(stream_view_));
}

template <typename i_t, typename f_t>
f_t pdlp_solver_t<i_t, f_t>::get_primal_weight_h() const
{
  return primal_weight_.value(stream_view_);
}

template <typename i_t, typename f_t>
f_t pdlp_solver_t<i_t, f_t>::get_step_size_h() const
{
  return step_size_.value(stream_view_);
}

template <typename i_t, typename f_t>
i_t pdlp_solver_t<i_t, f_t>::get_total_pdhg_iterations() const
{
  return pdhg_solver_.total_pdhg_iterations_;
}

template <typename i_t, typename f_t>
detail::pdlp_termination_strategy_t<i_t, f_t>&
pdlp_solver_t<i_t, f_t>::get_current_termination_strategy()
{
  return current_termination_strategy_;
}

#if MIP_INSTANTIATE_FLOAT
template class pdlp_solver_t<int, float>;

template __global__ void compute_weights_initial_primal_weight_from_squared_norms<float>(
  const float* b_vec_norm,
  const float* c_vec_norm,
  float* primal_weight,
  float* best_primal_weight);
#endif

#if MIP_INSTANTIATE_DOUBLE
template class pdlp_solver_t<int, double>;

template __global__ void compute_weights_initial_primal_weight_from_squared_norms<double>(
  const double* b_vec_norm,
  const double* c_vec_norm,
  double* primal_weight,
  double* best_primal_weight);
#endif

}  // namespace cuopt::linear_programming::detail
